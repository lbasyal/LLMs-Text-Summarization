{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook demonstrates the experimental setup for the Youtube Comment Summarizer with text-davinci-003 model from OpenAI ChatGPT.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-24T02:47:14.310943Z","iopub.execute_input":"2023-10-24T02:47:14.311377Z","iopub.status.idle":"2023-10-24T02:47:14.758448Z","shell.execute_reply.started":"2023-10-24T02:47:14.311343Z","shell.execute_reply":"2023-10-24T02:47:14.755809Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/service-account/youtube-video-402509-52111437b494.json\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Installing required libraries","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade pip \n!pip install nltk\n!pip install tenacity\n!pip install openai\n!pip install google-api-python-client\n!pip install pytube\n!pip install transformers\n!pip install python-dotenv\n!pip install google-auth-httplib2 \n!pip install google-auth-oauthlib","metadata":{"execution":{"iopub.status.busy":"2023-10-24T02:47:14.760368Z","iopub.execute_input":"2023-10-24T02:47:14.760877Z","iopub.status.idle":"2023-10-24T02:49:58.773256Z","shell.execute_reply.started":"2023-10-24T02:47:14.760842Z","shell.execute_reply":"2023-10-24T02:49:58.771468Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.1.2)\nCollecting pip\n  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.1.2\n    Uninstalling pip-23.1.2:\n      Successfully uninstalled pip-23.1.2\nSuccessfully installed pip-23.3.1\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nRequirement already satisfied: tenacity in /opt/conda/lib/python3.10/site-packages (8.2.2)\nCollecting openai\n  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai) (3.8.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.7.22)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\nDownloading openai-0.28.1-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: openai\nSuccessfully installed openai-0.28.1\nRequirement already satisfied: google-api-python-client in /opt/conda/lib/python3.10/site-packages (2.97.0)\nRequirement already satisfied: httplib2<1.dev0,>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client) (0.21.0)\nRequirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client) (2.20.0)\nRequirement already satisfied: google-auth-httplib2>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client) (0.1.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client) (2.11.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client) (3.0.1)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.59.1)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.16.0)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.26.15)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.0.9)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.4.8)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.7.22)\nCollecting pytube\n  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pytube\nSuccessfully installed pytube-15.0.0\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.0)\nRequirement already satisfied: google-auth-httplib2 in /opt/conda/lib/python3.10/site-packages (0.1.0)\nRequirement already satisfied: google-auth in /opt/conda/lib/python3.10/site-packages (from google-auth-httplib2) (2.20.0)\nRequirement already satisfied: httplib2>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-httplib2) (0.21.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-auth-httplib2) (1.16.0)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2>=0.15.0->google-auth-httplib2) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth->google-auth-httplib2) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth->google-auth-httplib2) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth->google-auth-httplib2) (4.9)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth->google-auth-httplib2) (1.26.15)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth->google-auth-httplib2) (0.4.8)\nRequirement already satisfied: google-auth-oauthlib in /opt/conda/lib/python3.10/site-packages (1.0.0)\nRequirement already satisfied: google-auth>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib) (2.20.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib) (1.3.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (4.9)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (1.16.0)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (1.26.15)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\nRequirement already satisfied: requests>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.31.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-auth-oauthlib) (0.4.8)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2023.7.22)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let's import the required libraries","metadata":{}},{"cell_type":"code","source":"from googleapiclient.discovery import build\nfrom pytube import extract\nfrom googleapiclient.errors import HttpError  # Import HttpError\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom google.oauth2 import service_account\n\nfrom dotenv import load_dotenv\n\n\nload_dotenv()\n\napi_server_name = \"youtube\"\napi_version = \"v3\"\n# # youtube_api_key = st.secrets['YOUTUBE_API_KEY']\n# access_token = st.secrets['OAUTH2_ACCESS_TOKEN'] # Update 'youtube_api_key' to 'access_token'\n\n# # Load secrets from Streamlit's secrets.toml file\n# client_id = st.secrets['CLIENT_ID']\n# client_secret = st.secrets['CLIENT_SECRET']\n\n\n# Function to obtain the YouTube service using OAuth 2.0\ndef start_youtube_service():\n    # # Create OAuth2 credentials flow using client ID and secret\n    # flow = InstalledAppFlow.from_client_secrets_file(\n    #     '/Users/lochanbasyal/Desktop/comments-summary-ml-project/client_secret_766725606755-nqto2u1e0jrsf4mbocul86pd6l0qjvun.apps.googleusercontent.com.json',\n    #     scopes=[\"https://www.googleapis.com/auth/youtube.force-ssl\"],\n    #     redirect_uri=\"http://localhost:55582\"  # Make sure it matches the one in Google Cloud Console\n    # )\n    # Load OAuth 2.0 credentials from the JSON file\n    credentials = service_account.Credentials.from_service_account_file(\n        '/kaggle/input/service-account/youtube-video-402509-52111437b494.json', scopes=[\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n    )\n    # Build and return the YouTube service using the obtained credentials\n    youtube = build(api_server_name, api_version, credentials=credentials)\n    \n    return youtube\n\ndef extract_video_id_from_link(url):\n    return extract.video_id(url)\n\ndef get_comments_thread(youtube, video_id, next_page_token):\n    results = youtube.commentThreads().list(\n        part=\"snippet,replies\",                     \n        videoId=video_id,\n        textFormat='plainText',\n        maxResults=100,\n        pageToken = next_page_token\n    ).execute()\n    return results\n\ndef load_comments_in_format(comments):\n    all_comments = []\n    all_comments_string = \"\"\n    for thread in comments[\"items\"]:\n        comment = {}\n        comment['content'] = thread['snippet']['topLevelComment']['snippet']['textOriginal']\n        all_comments_string = all_comments_string + comment['content']+\"\\n\"\n        replies = []\n        if 'replies' in thread:\n            for reply in thread['replies']['comments']:\n                reply_text = reply['snippet']['textOriginal']\n                all_comments_string = all_comments_string + reply_text+\"\\n\"\n                replies.append(reply_text)\n            comment['replies'] = replies\n        \n        all_comments.append(comment)\n    return all_comments_string\n\ndef fetch_comments(url):\n    youtube = start_youtube_service()\n    video_id = extract_video_id_from_link(url)\n    next_page_token = ''\n   \n    data = get_comments_thread(youtube, video_id, next_page_token)\n    if \"nextPageToken\" in data:\n        next_page_token = data[\"nextPageToken\"]\n    all_comments = load_comments_in_format(data)\n\n    while next_page_token:\n        data = get_comments_thread(youtube, video_id, next_page_token)\n        if \"nextPageToken\" in data:\n            next_page_token = data[\"nextPageToken\"]\n        else:\n            next_page_token = ''\n        all_comments = all_comments + load_comments_in_format(data)\n\n    #all_comments = load_comments_in_format(data) #\n    return all_comments","metadata":{"execution":{"iopub.status.busy":"2023-10-24T02:51:39.808218Z","iopub.execute_input":"2023-10-24T02:51:39.809433Z","iopub.status.idle":"2023-10-24T02:51:40.081275Z","shell.execute_reply.started":"2023-10-24T02:51:39.809384Z","shell.execute_reply":"2023-10-24T02:51:40.080082Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"url = \"https://www.youtube.com/watch?v=_0450d_WzqE\"\nfetch_comments(url)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T02:52:38.313145Z","iopub.execute_input":"2023-10-24T02:52:38.313560Z","iopub.status.idle":"2023-10-24T02:52:38.840919Z","shell.execute_reply.started":"2023-10-24T02:52:38.313525Z","shell.execute_reply":"2023-10-24T02:52:38.839581Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'He has accomplished all of this from doing Antern\\'s ML course, you can also join Antern Core ML course over here, we are offering this course at just 60 USD, no need to pay 1000s of dollars,  (Use Code AS60 for this :) Valid for 4 days only\\nAyush,  do aptitude classes in your youtube channel or in your antern website at reasonable price Because it\\'s essential for many jobs for candidate shortlisting. To prove his programing talent, one must perform good at aptitude, reasoning and  verbal. I think my point has been confessed.\\n@Gift Ibe No, you bought the correct course, there\\'s just a naming change :) don\\'t worry about that\\nHi, I just got the machine learning engineering course, instead of the Core ML. \\nCan I cancel and transfer the purchase?\\n@K 9 like it depends, if it is international then it can be  24 LPA\\nAyush what salary can we expect after completing this course.\\nAny range can you give.\\nPls reply 🙏🙏\\nGreat interview and good job on the project too!\\nIs it just me or Ayush is actually being Ranbir kapoor 😂\\nAyush im literally so late , can i register now I really want to learn machine learning. can i purchase it now. But i can\\'t see openings in registration. Ayush please reply. I have been waiting for these type of courses\\n@Ayush I am interested but after the training will you guide me to get freelancer Job I want you to know am from Nigeria I will be greatfull if you assist\\n9:20 No we can\\'t conclude the difference is in the teaching methods, the t-test only tells you if the difference is not by chance. For it to be the teaching methods you would have to assume that students have the same level of knowledge/intelligence for example.\\nHey Ayush, watch full video I have a doubt about how can we make such projects by using frontend and backend ? I\\'m working on some data science project of predication but only on the Jupyter note book if you read this comment please reply or make a video on it\\nhii\\r\\ni want to know it worth it to join the CS001 B04 batch today on the 29th July 2023?\\r\\ni want to join your core machine learning batch the CS001 B04, can i know when it was launched?\\r\\nbcz i despirately want to learn machine learning and need a guidance\\r\\nand will there be still 1 on 1 support and live classes still today\\r\\n??\\r\\nplz reply\\n@Sarthak Sarode Hi Sarthak, Support team is there just for x amount of hours on the website, we would be happy if our effort and time is respected, please note - there is doubt resolution along with help in interview prep and gig\\n@Ayush Singh will there be still 1 on 1 support and you will help us get our first paycheque, ihelp us with interview preparation and freelancing gig? and your support team doesnt respond at all\\nHi - It is worth to join the course, you can just go ahead learning from scratch, it might be that you\\'ve missed some live sessions, however you can get started because students are joining right now too,\\nHi ayush \\nI have two doubts regarding this course\\n1)  can i join this course now (because it\\'s 18 july 2023) \\n2)can i get antern  certificate after compeletion of this course??\\nHi, \\n\\n1. Yes, several people are joining right now as well because it\\'s an hybrid course where we release content every week followed by live session. \\n\\n2. Yes, you will get antern certificate and lors after completion. \\n\\nThanks\\nThe smile that ayush got while hearing his name from his student is so Good 😂\\ncan you explain how i can use python for geek book for machine learning.\\nArjun Tendulkar 😂\\nHey Ayush, I am currently student in Antern MLcourse. My only problem is my English communication skills. I understand and write English very well, but when it comes to speaking or communicating with someone, I struggle to manage. Could you please create a detailed video(road map) on how to improve our English? If you don\\'t have time to make a video, could you at least provide some tips through text? I would really appreciate it.\\n@Team Project 👍\\nJust watch some interview videos. Make yourself familiar. Learn the phrases that they use and how they structure their responses. English communication is very subjective.  A large part of learning anything is believing in yourself and \"normalizing\" stuff inside your head. You don`t need to be impressively good at it in general. You just need to get yourself familiar with the lingo of the niche/particular field you are interested in (interview communication here).\\nAlso, English is no barrier to getting a good job. There`s tonnes of people with broken English who bag nice placements. So while you`re making an effort to imporve your English skills, don`t get demotivated by the fact that you`re not already good at it. It`s only gonna be a plus here. You were never at a disadvantage in the first place! \\n\\n👍\\n@Future Tech Thank you for your suggestion broo👍\\nHi.\\nI read your comment and here to answer you\\nBroo, you can achieve this only by practicing. You just need to make a habit of speaking with anyone, if no one is available then just deliver a lecture on anything in your room or in the green field.\\n Continue listening, and learn new words every day and start speaking them.\\nWithin 3 months your speaking skill will be good as well.\\nHey ayush,ur accent and flow of speaking English is cool ♥️ it\\'ll be helpful if you share tips to improve communication\\nHey Ayush 👋, which stream are you choosing in 11th grade?\\nHow many programming languages do you know ayush ? Only python or you know other languages?\\nTop G Kid\\nfor a person learning a non circuital course in college ....is ML a better option to take vis a vis i am learning web developement side by side ...is that better than ML .. for a new comer\\nBahi yar tussi great ho.\\nAyush my question is if I wanna be an AI engineer so do I have to learn ML and DL ? and can you tell me how shall I start my journey !!\\nYup\\nHi can you solve this doubt... I\\'m working as a Rpa Developer (1.8,yrs exp)but left my job as I had no scope in project and thought to shift my domain as I\\'m in initial phase of my career.... but how should I approach as fresher to data domain\\ni also completed data i alreadly know all the answer fact!!!!!!!\\nWe want more interviews like this really love it!!\\nHey ayush great video , i have a doubt whether to learn directly  Ml during 1st year or learn Java dsa then development is various fields(web,app...) because i heard that product based companies are more interested in people with these skills OR to do Ml as you said that the demand for these skills are high.\\nAs a complete beginner what should i take a career in SDE or DATA SCIENTIST  \\nThanks for the wide aspect video :)\\n🙁\\nare the freelancing gigs opportunities provided by you?? and what after the course completion... will you provide internship opportunities?\\nYes, freelancing gigs are provided by me and placement assistance is also provided :)\\nI am from Pakistan\\nCan I take your course??\\nOur Younger professor Mr. ayush\\nYes, definitely, one can enrol into the course\\nI just watched this video and greatly appreciate the efforts of Ayush, who is dedicated to training his team at such a high level. And I have no words for Vishwas; he didn\\'t even appear underconfident at any moment. Once again, thank you so much Ayush and Team Antern for your tireless efforts.\\nThanks dude!!\\nYour most welcome\\nThanks a lot for your help.\\nhy piyush how, you maintain your physical health.....what you use to do ?\\nNothing as such, simple cardio maybe?\\nCompanies are asking for experience in data science ,as a fresher how we can get job. Please reply\\nThey are looking for the \"right\" talent :)\\nThis hairstyle is not looking good 🤧🤧\\nsorry but that was not intentional\\nHi, Ayush  really inspired by the work you have been doing. I wanted ask a question regarding the course.  I have 5 years of gap after my graduation will it be helpful for me if i enroll for the course like will i get any career opportunities in Data field ??\\nIt will definitely be helpful, we have so many students who have gaps and are able to learn successfully.\\nDid you learned DSA??\\nHey ayush, i have been learning to code from youtube from past 5+months, and  i have completeted python, pandas, numpy and done various projects and now i am learning matplotlib, \\nso should i cary on to learn from youtube or from your course, \\nplease tell which will be a better option \\n(Btw, currently i am in class 10th).\\nThanks ayush,\\n i will join your course from tomorrow, \\nBecause i also believe that your course would be personalised and  will also cover all the topics needed for it in reality as you are your self  a Data Scientist.\\nIf you have completed the projects in that then i suggest if you want personalized mentorship then course will be better as it teaches you base of it, you can also try out my newly launched course on regression analysis.\\nHey Ayush, Can you make a video on preparation of Interview. Btw the work you do can\\'t be expressed in words 😊\\nSure, Noted and thanks for your appreciation :)\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"Importing libraries","metadata":{}},{"cell_type":"code","source":"import nltk\nimport time\nimport openai\nimport transformers\nfrom tenacity import (\n    retry,\n    stop_after_attempt,\n    wait_random_exponential,\n)\nfrom dotenv import load_dotenv\nfrom typing import List\n\n\nload_dotenv()\nnltk.download('punkt')\napi_key='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'\nopenai.api_key = api_key\n\ndef text_to_chunks(input_text: str, tokenizer: transformers.PreTrainedTokenizer, max_token_sz: int = 2000, overlapping_sentences: int = 10) -> List[str]:\n    sentences = nltk.sent_tokenize(input_text)\n    chunks = []\n\n    first_sentence = 0\n    last_sentence = 0\n    while last_sentence <= len(sentences) - 1:\n        last_sentence = first_sentence\n        chunk_parts = []\n        chunk_size = 0\n        for sentence in sentences[first_sentence:]:\n            sentence_sz = len(tokenizer.encode(sentence))\n            if chunk_size + sentence_sz > max_token_sz:\n                break\n            \n            chunk_parts.append(sentence)\n            chunk_size += sentence_sz\n            last_sentence += 1\n\n        chunks.append(\" \".join(chunk_parts))\n        first_sentence = last_sentence - overlapping_sentences\n    return chunks\n\n@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(3))\ndef completion_with_backoff(**kwargs):\n    return openai.Completion.create(**kwargs)\n@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(3))\ndef completion_with_backoff(**kwargs):\n    try:\n        return openai.Completion.create(**kwargs)\n    except openai.error.RateLimitError as e:\n        st.warning(\"Rate limit exceeded. Waiting for rate limit reset...\")\n        time.sleep(60)  # Wait for a minute\n        st.info(\"Rate limit has been reset. Resuming...\")\n        raise e  # Re-raise the exception to trigger retry\n\ndef summarize_comment(subtitle: str, max_tokens: int = 524, temperature: int = 0) -> str:\n    response = openai.Completion.create(\n        model=\"text-davinci-003\",\n        prompt=f'Provide a concise summary of the subtitle.\"'\n        f\"\\n###\\nSubtitle:{subtitle}\\n###\\n-\",\n        temperature=temperature,\n        max_tokens=max_tokens,\n        top_p=1,\n        frequency_penalty=0,\n        presence_penalty=0,\n    )\n\n    return response['choices'][0]['text'].strip()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:22:02.385635Z","iopub.execute_input":"2023-10-24T03:22:02.386116Z","iopub.status.idle":"2023-10-24T03:22:02.408361Z","shell.execute_reply.started":"2023-10-24T03:22:02.386076Z","shell.execute_reply":"2023-10-24T03:22:02.406880Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\ntext = fetch_comments(url)\ntokenizer = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\nchunks = text_to_chunks(text, tokenizer)\nprint(\"Chunks list size: \", len(chunks))    # TODO: Remove this\nsummaries = \"\"\nfor chunk in chunks:\n    summary = summarize_comment(chunk)\n    summaries = summaries + summary\nfinal_summary = summarize_comment(summaries)\nprint(final_summary)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:22:04.806792Z","iopub.execute_input":"2023-10-24T03:22:04.807252Z","iopub.status.idle":"2023-10-24T03:23:03.974133Z","shell.execute_reply.started":"2023-10-24T03:22:04.807215Z","shell.execute_reply":"2023-10-24T03:23:03.972257Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Chunks list size:  2\nAyush Singh has achieved success in programming and machine learning through Antern's ML course, which is offered at a discounted price of 60 USD. He encourages aptitude classes to be offered at a reasonable price, as it is essential for many jobs. He provides advice on how to improve English communication skills, how to gain experience in data science, and how to get a job as a fresher. He also answers questions about the course, such as whether it is worth joining, if there is 1-on-1 support, and if a certificate is provided upon completion. He recommends his course for personalized mentorship and offers to make a video on interview preparation.\n","output_type":"stream"}]},{"cell_type":"code","source":"def summarize_comment(subtitle: str, max_tokens: int = 524, temperature: int = 0.7) -> str:\n    response = openai.Completion.create(\n        model=\"text-davinci-003\",\n        prompt=f'Provide a concise summary of the comments.\"'\n        f\"\\n###\\nSubtitle:{subtitle}\\n###\\n-\",\n        temperature=temperature,\n        max_tokens=max_tokens,\n        top_p=1,\n        frequency_penalty=0,\n        presence_penalty=0,\n    )\n\n    return response['choices'][0]['text'].strip()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:35:01.599336Z","iopub.execute_input":"2023-10-24T03:35:01.599740Z","iopub.status.idle":"2023-10-24T03:35:01.609307Z","shell.execute_reply.started":"2023-10-24T03:35:01.599709Z","shell.execute_reply":"2023-10-24T03:35:01.607218Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"summaries = \"\"\nfor chunk in chunks:\n    summary = summarize_comment(chunk)\n    summaries = summaries + summary\nfinal_summary = summarize_comment(summaries)\nprint(final_summary)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:36:15.082575Z","iopub.execute_input":"2023-10-24T03:36:15.083157Z","iopub.status.idle":"2023-10-24T03:36:19.316799Z","shell.execute_reply.started":"2023-10-24T03:36:15.083101Z","shell.execute_reply":"2023-10-24T03:36:19.315386Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Ayush Singh provides an affordable course to teach the fundamentals of Machine Learning, with 1-on-1 support, interview prep, and freelancing gig assistance after completion. He also offers advice on physical health, getting a job in data science as a fresher, and learning to code. Ayush's course also includes a video on how to prepare for an interview.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2nd case for experiment","metadata":{}},{"cell_type":"code","source":"url = \"https://www.youtube.com/watch?v=3VWS4x0AxIk\"\nfetch_comments(url)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:42:33.824925Z","iopub.execute_input":"2023-10-24T03:42:33.825507Z","iopub.status.idle":"2023-10-24T03:42:35.185606Z","shell.execute_reply.started":"2023-10-24T03:42:33.825457Z","shell.execute_reply":"2023-10-24T03:42:35.183028Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"\"Damn you do sailing before a test.\\nyoure from boston ?\\nSuper content. Keep it up\\nIs there any entrance exam for undergrad??\\nhey Ani, I'm Farhan. If all goes well or at least end goes well then I will be very happy to meet u on campus maybe after 1 and half years.\\nREMEMBER ME\\nnice job bud, despite im a gamer but your video still recommended to me\\nI am 330 subscriber of your YT channel bro\\nHey Ani! Great video dude. It was super fun to watch the video. Is there a way to contact you? like a mail or something? Just to get to know more about such stuff. It would be great if we can talk or chat, as I needed some more info. Nice video...Keep going!!\\nMan if you say how you got to mit? That will be really helpful\\nAre you of Indian origin?\\nmostly american\\nmake a video on how you got into mit please\\n\\n\\n\\nrequest from india😋🤗😜\\nYou’ll be big one day man! Keep going!\\nthanks for your video, where are\\n you from\\nAlso would love to hear your journey ❤\\nHey Ani! I'm also Ani. Thank you for sharing your day with us. The video was really amazing and I can't wait for more of them 🔥\\nhello to every ani i am also ani 😂.\\nHi ani, I am sar\\nhey ani , i am not ani\\nHey Ani, I’m also Ani 😂\\n@ANINDITA MOHANTY Lol nice 😂, btw thanks to you guys for reminding me this video again and again 🙏🏻\\nHah I remember you from the “asking mit students what they are listening to” video,  and this just randomly popped up on my recommendations.\\nI enjoyed this video so much i started looking for more but realised it was your first 🥺 I have feeling you're gonna go far!\\nEn español porfavor 🙏\\nDreams of many but the destination of few. The MIT\\nHow to get into MIT as a foreign student ?\\nwhat indian languages do you know?\\nhi i am hansraj from india i am in 11th grade and i do not know how to join mit if you could help me that will be wonderful\\n\\u200b@Saket singh just because if you are in iit that doesn't mean iit can be compared to MIT, you can see the difference between IIT and MIT which has been explained by non other than jee advanced air1 chirag falore, any one who worked hard for two years can easily crack jee advanced nd get into iits while the admission process of MIT is entirely different there are five processes\\n(1)  academic career  class 9 to 12\\n(2) extracurricular activities\\n(3) essays\\n(4) SAT/ACT Score\\n(5) interview\\n\\nYou have to be extremely smart enough  to get admission there, nearly 4-5 students get selected into MIT from India every year, \\nI know iits are a brand of India and no doubt jee advanced is extremely tough but it's level is below the levels of iPho,icho,imo , to get admission into MIT you have to win gold/silver medal in international Olympiad and remember there is no reservations unlike iits.\\n\\n\\nI hope in future IITs can be compared to MIT but as of now comparing IITs with MIT doens't makes any sense.\\n@Saket singh another iit *ickrider\\n@Krishna MIT how can you help how many of your students made it into mit? And if you are a private counsellor then you will charge at least 5lkhs\\nAre not you having google\\nFocus on SAT, Academics, Extracurriculars and get help from us\\nThe video was wholesome . It was fun and insightful. Subscribed to know more of you😊❤\\nIt was really amazing man...Hoping to see more.\\nsuPer cool vlog! \\nthe dome looks fantastic at night, OMG!\\nAre you indian?\\n@Warrior how do you know\\nRobert Clive the founder of IndiaWTF you know about his faith\\nO i forgot it's today's Trend to sound cool 😎 as an atheist.\\n@Morari Bapu American hindu\\nAmerican forever\\nBrooo....Thisss Is The I Was Searching For Can't Expresss It !!\\nPleaseee Upload Next Video Of Your Room Tourr..\\nBTW - how can i contact you??\\nThankss For The Fantasticc Video😀\\n❤\\n@Satya anand ?\\nYou can't\\nDo make a stats and ECs video please 🙏🏻\\nDo you plan on doing a q&a for prospective students in the future?\\n@Anirudh Valiveru Iam interested\\nIf enough people would be interested I would love to!\\nGreat video to capture memories down the lane . Keep rocking Anirudh.\\nAwesome job Ani love the visuals and the music choice!!\\nThanks maxi!\\nNice video !\\nCourse VI is so cool\\nOur official MIT vlogger 😀\\nNicely done !!!\\nThank you Tushar uncle! Glad you enjoyed it!\\nThis is amazing! 🔥\\nThanks veer!\\nVery nice and useful info to learn about MIT with nice insights and pretty fall colors. Thanks for sharing your day!\\n@Spirit ok\\n@Satyavivekanand Battula yes,so ?\\n@Spirit okay. Great. You're from telengana?\\n@Satyavivekanand Battula telugu telusu antunna\\n@Spirit what do you know ? Anti telusu bro ?\\nWhat a spicy lad 🔥🔥🔥\\nYessir Gerardo, glad you enjoyed it!\\nOmg super cool\\nWhat a cool guy!\\nVery good editing bro!! Fun video too.. interesting\\nThank you!\\ngreat video!\\nThanks Dev, glad you enjoyed it!\\nYoooo awesome vlog!\\nThanks divya!\\nWoww so exciting\\nThanks ritika!\\n\""},"metadata":{}}]},{"cell_type":"code","source":"import transformers\ntext = fetch_comments(url)\ntokenizer = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\nchunks = text_to_chunks(text, tokenizer)\nprint(\"Chunks list size: \", len(chunks))    # TODO: Remove this\nsummaries = \"\"\nfor chunk in chunks:\n    summary = summarize_comment(chunk)\n    summaries = summaries + summary\nfinal_summary = summarize_comment(summaries)\nprint(final_summary)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-24T03:49:30.100174Z","iopub.execute_input":"2023-10-24T03:49:30.100562Z","iopub.status.idle":"2023-10-24T03:49:34.831544Z","shell.execute_reply.started":"2023-10-24T03:49:30.100527Z","shell.execute_reply":"2023-10-24T03:49:34.830293Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Chunks list size:  1\nThis subtitle provides a summary of Ani's video, in which he answered questions about the admission process to MIT, his Indian heritage, and other related topics. He encouraged viewers to focus on their SATs, academics, and extracurricular activities and offered to answer any further questions.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"why subtitle, since I provided subtitle in the prompt, but this is actually comments.","metadata":{}},{"cell_type":"markdown","source":"Chunks list size:1, it means no need to do double call the api for summarization. In some larger comments, there might be more number of chunks where calling api for summarization of each chunk and then final call on the combination would be fine to produce good result. However, if there is a single chunk, it's ok to have one api call.","metadata":{}},{"cell_type":"code","source":"import transformers\ntext = fetch_comments(url)\ntokenizer = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\nchunks = text_to_chunks(text, tokenizer)\nprint(\"Chunks list size: \", len(chunks))    # TODO: Remove this\nsummary = summarize_comment(chunk,524,0.1)\nprint(summary)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:06:05.002974Z","iopub.execute_input":"2023-10-24T04:06:05.003421Z","iopub.status.idle":"2023-10-24T04:06:08.146429Z","shell.execute_reply.started":"2023-10-24T04:06:05.003385Z","shell.execute_reply":"2023-10-24T04:06:08.145423Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Chunks list size:  1\nThis video is a vlog of Ani's day at MIT, showing the campus and his activities. It also includes comments from viewers asking questions about how to get into MIT, what Indian languages Ani knows, and how to contact him. Ani also answers questions about the differences between IITs and MIT, and provides advice on how to get into MIT.\n","output_type":"stream"}]},{"cell_type":"code","source":"summary = summarize_comment(chunk,524,0.7)\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:08:26.614496Z","iopub.execute_input":"2023-10-24T04:08:26.614966Z","iopub.status.idle":"2023-10-24T04:08:53.921820Z","shell.execute_reply.started":"2023-10-24T04:08:26.614929Z","shell.execute_reply":"2023-10-24T04:08:53.920538Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"The video is about Ani, a student at MIT, who shares her day with the viewers. There is discussion of entrance exams, how to get into MIT as a foreign student, and what Indian languages Ani knows. Other viewers comment on Ani's journey, her video, and ask about her background. There is also discussion of the different processes for getting into MIT, such as academic career, extra-curricular activities, essays, SAT/ACT scores, and interviews. Some viewers request a stats and ECs video, and a Q&A for prospective students.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"3rd case","metadata":{}},{"cell_type":"code","source":"url = \"https://www.youtube.com/watch?v=0JUN9aDxVmI\"","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:29:50.127629Z","iopub.execute_input":"2023-10-24T04:29:50.128086Z","iopub.status.idle":"2023-10-24T04:29:50.133454Z","shell.execute_reply.started":"2023-10-24T04:29:50.128037Z","shell.execute_reply":"2023-10-24T04:29:50.132386Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def summarize_comment(comments: str, max_tokens: int = 524, temperature: int = 0.7) -> str:\n    response = openai.Completion.create(\n        model=\"text-davinci-003\",\n        prompt=f'Provide a concise summary of the comments.\"'\n        f\"\\n###\\nComments:{comments}\\n###\\n-\",\n        temperature=temperature,\n        max_tokens=max_tokens,\n        top_p=1,\n        frequency_penalty=0,\n        presence_penalty=0,\n    )\n\n    return response['choices'][0]['text'].strip()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:30:35.054140Z","iopub.execute_input":"2023-10-24T04:30:35.054578Z","iopub.status.idle":"2023-10-24T04:30:35.062278Z","shell.execute_reply.started":"2023-10-24T04:30:35.054543Z","shell.execute_reply":"2023-10-24T04:30:35.060906Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import transformers\ntext = fetch_comments(url)\ntokenizer = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\nchunks = text_to_chunks(text, tokenizer)\nprint(\"Chunks list size: \", len(chunks))    # TODO: Remove this\n# summary = summarize_comment(chunk,524,0.1)\n# print(summary)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:31:06.366698Z","iopub.execute_input":"2023-10-24T04:31:06.367156Z","iopub.status.idle":"2023-10-24T04:31:07.257653Z","shell.execute_reply.started":"2023-10-24T04:31:06.367120Z","shell.execute_reply":"2023-10-24T04:31:07.255595Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_comments\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mGPT2TokenizerFast\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m chunks \u001b[38;5;241m=\u001b[39m text_to_chunks(text, tokenizer)\n","Cell \u001b[0;32mIn[4], line 75\u001b[0m, in \u001b[0;36mfetch_comments\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     72\u001b[0m video_id \u001b[38;5;241m=\u001b[39m extract_video_id_from_link(url)\n\u001b[1;32m     73\u001b[0m next_page_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 75\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mget_comments_thread\u001b[49m\u001b[43m(\u001b[49m\u001b[43myoutube\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_page_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnextPageToken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m     77\u001b[0m     next_page_token \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnextPageToken\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","Cell \u001b[0;32mIn[4], line 49\u001b[0m, in \u001b[0;36mget_comments_thread\u001b[0;34m(youtube, video_id, next_page_token)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_comments_thread\u001b[39m(youtube, video_id, next_page_token):\n\u001b[1;32m     43\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43myoutube\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommentThreads\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msnippet,replies\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                     \u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvideoId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvideo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtextFormat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplainText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxResults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpageToken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnext_page_token\u001b[49m\n\u001b[0;32m---> 49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/googleapiclient/http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    936\u001b[0m     callback(resp)\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n","\u001b[0;31mHttpError\u001b[0m: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=0JUN9aDxVmI&textFormat=plainText&maxResults=100&pageToken=&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.', 'domain': 'youtube.commentThread', 'reason': 'commentsDisabled', 'location': 'videoId', 'locationType': 'parameter'}]\">"],"ename":"HttpError","evalue":"<HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=0JUN9aDxVmI&textFormat=plainText&maxResults=100&pageToken=&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.', 'domain': 'youtube.commentThread', 'reason': 'commentsDisabled', 'location': 'videoId', 'locationType': 'parameter'}]\">","output_type":"error"}]},{"cell_type":"markdown","source":"Perfect, I took the video having comment disabled.","metadata":{}},{"cell_type":"markdown","source":"4th case","metadata":{}},{"cell_type":"code","source":"url = \"https://www.youtube.com/watch?v=eVOymNdbNJw\"","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:46:02.299898Z","iopub.execute_input":"2023-10-24T04:46:02.300328Z","iopub.status.idle":"2023-10-24T04:46:02.309109Z","shell.execute_reply.started":"2023-10-24T04:46:02.300286Z","shell.execute_reply":"2023-10-24T04:46:02.304356Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def summarize_comment(comments: str, max_tokens: int = 524, temperature: int = 0.7) -> str:\n    response = openai.Completion.create(\n        model=\"text-davinci-003\",\n        prompt=f'Provide a concise summary of the comments.\"'\n        f\"\\n###\\nComments:{comments}\\n###\\n-\",\n        temperature=temperature,\n        max_tokens=max_tokens,\n        top_p=1,\n        frequency_penalty=0,\n        presence_penalty=0,\n    )\n\n    return response['choices'][0]['text'].strip()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:46:02.714374Z","iopub.execute_input":"2023-10-24T04:46:02.715032Z","iopub.status.idle":"2023-10-24T04:46:02.722854Z","shell.execute_reply.started":"2023-10-24T04:46:02.714985Z","shell.execute_reply":"2023-10-24T04:46:02.721656Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import transformers\ntext = fetch_comments(url)\ntokenizer = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\nchunks = text_to_chunks(text, tokenizer)\nprint(\"Chunks list size: \", len(chunks))    # TODO: Remove this\n# summary = summarize_comment(chunk,524,0.1)\n# print(summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:46:03.950288Z","iopub.execute_input":"2023-10-24T04:46:03.950696Z","iopub.status.idle":"2023-10-24T04:46:05.391034Z","shell.execute_reply.started":"2023-10-24T04:46:03.950662Z","shell.execute_reply":"2023-10-24T04:46:05.389497Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Chunks list size:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"summary = summarize_comment(chunks)\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:46:08.686239Z","iopub.execute_input":"2023-10-24T04:46:08.686637Z","iopub.status.idle":"2023-10-24T04:46:10.128333Z","shell.execute_reply.started":"2023-10-24T04:46:08.686606Z","shell.execute_reply":"2023-10-24T04:46:10.127128Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"The comments express admiration for a vlog, appreciation for Nepal's beauty, and love for the vlog's creator, \"Sisan Dai.\" They also express excitement to start the day with the vlog and admiration for the vlog's \"masterpiece.\"\n","output_type":"stream"}]},{"cell_type":"code","source":"summary = summarize_comment(chunks,524,0.1)\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:48:13.615437Z","iopub.execute_input":"2023-10-24T04:48:13.615850Z","iopub.status.idle":"2023-10-24T04:48:14.630171Z","shell.execute_reply.started":"2023-10-24T04:48:13.615811Z","shell.execute_reply":"2023-10-24T04:48:14.628886Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"People are expressing their admiration for the vlog and the beauty of Nepal, as well as their love for the vlogger. They are also wishing them a good morning and sending lots of love.\n","output_type":"stream"}]},{"cell_type":"code","source":"summary = summarize_comment(chunks,50,0.1)\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:49:36.090276Z","iopub.execute_input":"2023-10-24T04:49:36.090716Z","iopub.status.idle":"2023-10-24T04:49:43.905537Z","shell.execute_reply.started":"2023-10-24T04:49:36.090680Z","shell.execute_reply":"2023-10-24T04:49:43.904435Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"The comments are expressing admiration for a vlog by Sisan Dai, praising the beauty of Nepal, and expressing love and support for Sisan Dai.\n","output_type":"stream"}]},{"cell_type":"code","source":"summary = summarize_comment(chunks,50,0.1)\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:50:14.566462Z","iopub.execute_input":"2023-10-24T04:50:14.566876Z","iopub.status.idle":"2023-10-24T04:50:15.523608Z","shell.execute_reply.started":"2023-10-24T04:50:14.566845Z","shell.execute_reply":"2023-10-24T04:50:15.522131Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"The comments are expressing appreciation for the vlog and admiration for the beauty of Nepal. They are also expressing love and support for the vlogger, Sisan Dai.\n","output_type":"stream"}]},{"cell_type":"code","source":"# summary = summarize_comment(chunks,50,0.1)\n# print(summary)\n# all most similar result in the above cases","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:51:35.856528Z","iopub.execute_input":"2023-10-24T04:51:35.856933Z","iopub.status.idle":"2023-10-24T04:51:35.862199Z","shell.execute_reply.started":"2023-10-24T04:51:35.856901Z","shell.execute_reply":"2023-10-24T04:51:35.861103Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"## 5th case","metadata":{}},{"cell_type":"code","source":"#let me change the prompt engineering part","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:53:20.866667Z","iopub.execute_input":"2023-10-24T04:53:20.867115Z","iopub.status.idle":"2023-10-24T04:53:20.872682Z","shell.execute_reply.started":"2023-10-24T04:53:20.867081Z","shell.execute_reply":"2023-10-24T04:53:20.871463Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def summarize_comment(comments: str, max_tokens: int = 524, temperature: int = 0.7) -> str:\n    response = openai.Completion.create(\n        model=\"text-davinci-003\",\n        prompt=f'Provide a brief summary of the comments in five main points.\"'\n        f\"\\n###\\nComments:{comments}\\n###\\n-\",\n        temperature=temperature,\n        max_tokens=max_tokens,\n        top_p=1,\n        frequency_penalty=0,\n        presence_penalty=0,\n    )\n\n    return response['choices'][0]['text'].strip()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:54:44.184624Z","iopub.execute_input":"2023-10-24T04:54:44.185061Z","iopub.status.idle":"2023-10-24T04:54:44.193594Z","shell.execute_reply.started":"2023-10-24T04:54:44.185012Z","shell.execute_reply":"2023-10-24T04:54:44.192201Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"url = \"https://www.youtube.com/watch?v=DxREm3s1scA&t=52s\"","metadata":{"execution":{"iopub.status.busy":"2023-10-24T04:56:52.996514Z","iopub.execute_input":"2023-10-24T04:56:52.996947Z","iopub.status.idle":"2023-10-24T04:56:53.002840Z","shell.execute_reply.started":"2023-10-24T04:56:52.996914Z","shell.execute_reply":"2023-10-24T04:56:53.001478Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import transformers\ntext = fetch_comments(url)\ntokenizer = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\nchunks = text_to_chunks(text, tokenizer)\nprint(\"Chunks list size: \", len(chunks))    # TODO: Remove this\n# summary = summarize_comment(chunk,524,0.1)\n# print(summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:00:17.147076Z","iopub.execute_input":"2023-10-24T05:00:17.147490Z","iopub.status.idle":"2023-10-24T05:00:40.250597Z","shell.execute_reply.started":"2023-10-24T05:00:17.147458Z","shell.execute_reply":"2023-10-24T05:00:40.249487Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Chunks list size:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"summary = summarize_comment(chunks,524,0.1)\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:05:10.489138Z","iopub.execute_input":"2023-10-24T05:05:10.489559Z","iopub.status.idle":"2023-10-24T05:05:11.538811Z","shell.execute_reply.started":"2023-10-24T05:05:10.489528Z","shell.execute_reply":"2023-10-24T05:05:11.537621Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"The comment acknowledges a legitimate claim.\n- The comment does not provide further details.\n- The comment does not provide an opinion.\n- The comment does not provide a solution.\n- The comment suggests that there is more to discuss.\n","output_type":"stream"}]},{"cell_type":"code","source":"def summarize_comment(comments: str, max_tokens: int = 524, temperature: int = 0.7) -> str:\n    response = openai.Completion.create(\n        model=\"text-davinci-003\",\n        prompt=f'Provide a concise summary of the comments'\n        f\"\\n###\\nComments:{comments}\\n###\\n-\",\n        temperature=temperature,\n        max_tokens=max_tokens,\n        top_p=1,\n        frequency_penalty=0,\n        presence_penalty=0,\n    )\n\n    return response['choices'][0]['text'].strip()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:07:29.004992Z","iopub.execute_input":"2023-10-24T05:07:29.005439Z","iopub.status.idle":"2023-10-24T05:07:29.013296Z","shell.execute_reply.started":"2023-10-24T05:07:29.005398Z","shell.execute_reply":"2023-10-24T05:07:29.012112Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"fetch_comments(url)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:08:00.088932Z","iopub.execute_input":"2023-10-24T05:08:00.089416Z","iopub.status.idle":"2023-10-24T05:08:21.420031Z","shell.execute_reply.started":"2023-10-24T05:08:00.089381Z","shell.execute_reply":"2023-10-24T05:08:21.418878Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"'First\\nFair enough. Legitimate claim\\nNext\\n'"},"metadata":{}}]},{"cell_type":"code","source":"import transformers\ntext = fetch_comments(url)\ntokenizer = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\nchunks = text_to_chunks(text, tokenizer)\nprint(\"Chunks list size: \", len(chunks))    # TODO: Remove this\n# summary = summarize_comment(chunk,524,0.1)\n# print(summary)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from googleapiclient.discovery import build\nfrom pytube import extract\nfrom googleapiclient.errors import HttpError  # Import HttpError\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom google.oauth2 import service_account\n\nfrom dotenv import load_dotenv\n\n\nload_dotenv()\n\napi_server_name = \"youtube\"\napi_version = \"v3\"\n# # youtube_api_key = st.secrets['YOUTUBE_API_KEY']\n# access_token = st.secrets['OAUTH2_ACCESS_TOKEN'] # Update 'youtube_api_key' to 'access_token'\n\n# # Load secrets from Streamlit's secrets.toml file\n# client_id = st.secrets['CLIENT_ID']\n# client_secret = st.secrets['CLIENT_SECRET']\n\n\n# Function to obtain the YouTube service using OAuth 2.0\ndef start_youtube_service():\n    # # Create OAuth2 credentials flow using client ID and secret\n    # flow = InstalledAppFlow.from_client_secrets_file(\n    #     '/Users/lochanbasyal/Desktop/comments-summary-ml-project/client_secret_766725606755-nqto2u1e0jrsf4mbocul86pd6l0qjvun.apps.googleusercontent.com.json',\n    #     scopes=[\"https://www.googleapis.com/auth/youtube.force-ssl\"],\n    #     redirect_uri=\"http://localhost:55582\"  # Make sure it matches the one in Google Cloud Console\n    # )\n    # Load OAuth 2.0 credentials from the JSON file\n    credentials = service_account.Credentials.from_service_account_file(\n        '/kaggle/input/service-account/youtube-video-402509-52111437b494.json', scopes=[\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n    )\n    # Build and return the YouTube service using the obtained credentials\n    youtube = build(api_server_name, api_version, credentials=credentials)\n    \n    return youtube\n\ndef extract_video_id_from_link(url):\n    return extract.video_id(url)\n\ndef get_comments_thread(youtube, video_id, next_page_token):\n    results = youtube.commentThreads().list(\n        part=\"snippet,replies\",                     \n        videoId=video_id,\n        textFormat='plainText',\n        maxResults=100,\n        pageToken = next_page_token\n    ).execute()\n    return results\n\ndef load_comments_in_format(comments):\n    all_comments = []\n    all_comments_string = \"\"\n    for thread in comments[\"items\"]:\n        comment = {}\n        comment['content'] = thread['snippet']['topLevelComment']['snippet']['textOriginal']\n        all_comments_string = all_comments_string + comment['content']+\"\\n\"\n        replies = []\n        if 'replies' in thread:\n            for reply in thread['replies']['comments']:\n                reply_text = reply['snippet']['textOriginal']\n                all_comments_string = all_comments_string + reply_text+\"\\n\"\n                replies.append(reply_text)\n            comment['replies'] = replies\n        \n        all_comments.append(comment)\n    return all_comments_string\n\ndef fetch_comments(url):\n    youtube = start_youtube_service()\n    video_id = extract_video_id_from_link(url)\n    next_page_token = ''\n   \n    data = get_comments_thread(youtube, video_id, next_page_token)\n    if \"nextPageToken\" in data:\n        next_page_token = data[\"nextPageToken\"]\n    all_comments = load_comments_in_format(data)\n\n    while next_page_token:\n        data = get_comments_thread(youtube, video_id, next_page_token)\n        if \"nextPageToken\" in data:\n            next_page_token = data[\"nextPageToken\"]\n        else:\n            next_page_token = ''\n        all_comments = all_comments + load_comments_in_format(data)\n\n    all_comments = load_comments_in_format(data)\n    return all_comments","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:12:50.330358Z","iopub.execute_input":"2023-10-24T05:12:50.330778Z","iopub.status.idle":"2023-10-24T05:12:50.349263Z","shell.execute_reply.started":"2023-10-24T05:12:50.330736Z","shell.execute_reply":"2023-10-24T05:12:50.347873Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"url = \"https://www.youtube.com/watch?v=rB39Q60BqpU\"","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:14:55.630399Z","iopub.execute_input":"2023-10-24T05:14:55.630845Z","iopub.status.idle":"2023-10-24T05:14:55.636153Z","shell.execute_reply.started":"2023-10-24T05:14:55.630809Z","shell.execute_reply":"2023-10-24T05:14:55.634937Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"fetch_comments(url)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:14:58.268467Z","iopub.execute_input":"2023-10-24T05:14:58.269628Z","iopub.status.idle":"2023-10-24T05:14:58.636426Z","shell.execute_reply.started":"2023-10-24T05:14:58.269578Z","shell.execute_reply":"2023-10-24T05:14:58.635016Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"\"He seems to feel the worries Ness for leaving this planet Earth.\\nMr Elon Musk I wishing you 🙏 all the best to get all the way through. YOU are great person like Mr Donald Trump 😀 👍 ❤️.\\nElon I taking all my work  out I suck of all u poeple  now there nothing no more\\nSo hard . Calculations have to be symmetrical perfect.\\nPossible\\nSpace exploration is vital as our Earth we live in is in space 🌌🚀 to what extent of exploration  could be an issue hoping not to overwhelm Earth and humanity in reality indeed do what you love to do\\nVery humble and looking to the future for answer to make the world a better place in the future 👍🤓🙏❤️ that.\\nLove always from me ❤️❤️.where are you from??🌹🌹\\n🙏🏻🙏🏻🙏🏻🙏🏻❤️❤️❤️❤️🤗🤗🤗🤗\\nLove always from me ❤️❤️.where are you from?❤️🌹\\nElon Musk I'm really proud of you for what you love do and you really enjoy doing it too I'm so happy for you Elon Musk love❤️💙❤️\\nLove always from me ❤️❤️.where are you from??🌹🌹\\n❤❤❤❤❤😊😊🎉😅😅😅\\nLove always from me ❤️❤️.where are you from?❤️🌹\\nNew again Thanks Musk\\nLove always from me ❤️❤️.where are you from?❤️🌹\\nKeep searching, pathfinder ❤\\n@Elon Musk from another galaxy..\\nLove always from me ❤️❤️.where are you from??🌹🌹\\nBaby am  thea ❤❤tongetha\\nLove always from me ❤️❤️.where are you from?❤️🌹\\nI support him...being a human being and also being a fan...he is way better then anyone...but who stand on the top...people keep looking to find a way to pull that person leg...try to make a small incident hugh..then messing here and there...but he will become more strong...in the end..the person who is right win in the end...it's just so simple.\\nLove always from me ❤️❤️.where are you from??🌹🌹\\n❤❤❤❤❤❤❤\\nLove always from me ❤️❤️.where are you from?❤️🌹\\nLove always from me ❤️❤️.where\\n@ MOTIVATIONAL SPEECH\\nBest Ilon Mask\\nLove always from me ❤️❤️.where are you from?❤️🌹\\n🫂❤️\\nLove always from me ❤️❤️.where are you from?❤️🌹\\nThank you Musk\\nLove always from me ❤️❤️.where are you from?❤️🌹\\nZelle me elon\\nYeah its important to do something that inspires you, and drives you. Otherwise its just a waste of time.\\nLove always from me ❤️❤️.where are you from??🌹🌹\\nI feel sorry for Elon. He seems like a lost man far from God 😢\\nSometimes your heroes do not like you… and like them still you should…\\n\""},"metadata":{}}]},{"cell_type":"code","source":"import transformers\ntext = fetch_comments(url)\ntokenizer = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\nchunks = text_to_chunks(text, tokenizer)\nprint(\"Chunks list size: \", len(chunks))    # TODO: Remove this\n# summary = summarize_comment(chunks,524,0.1)\n# print(summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:16:40.293816Z","iopub.execute_input":"2023-10-24T05:16:40.294249Z","iopub.status.idle":"2023-10-24T05:16:41.088586Z","shell.execute_reply.started":"2023-10-24T05:16:40.294219Z","shell.execute_reply":"2023-10-24T05:16:41.087205Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Chunks list size:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"summary = summarize_comment(chunks,524,0.1)\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:17:12.538188Z","iopub.execute_input":"2023-10-24T05:17:12.538593Z","iopub.status.idle":"2023-10-24T05:17:26.109323Z","shell.execute_reply.started":"2023-10-24T05:17:12.538563Z","shell.execute_reply":"2023-10-24T05:17:26.108095Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"The comments express admiration for Elon Musk and his work, wishing him luck in his endeavors and offering support. They also discuss the importance of space exploration and the need to make the world a better place. Finally, they encourage Musk to do what he loves and to stay motivated.\n","output_type":"stream"}]},{"cell_type":"code","source":"# https://www.youtube.com/watch?v=Hd_ptbiPoXM\nurl = \"https://www.youtube.com/watch?v=Hd_ptbiPoXM\"","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:22:20.122113Z","iopub.execute_input":"2023-10-24T05:22:20.122530Z","iopub.status.idle":"2023-10-24T05:22:20.127943Z","shell.execute_reply.started":"2023-10-24T05:22:20.122492Z","shell.execute_reply":"2023-10-24T05:22:20.126757Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"fetch_comments(url)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:23:37.676216Z","iopub.execute_input":"2023-10-24T05:23:37.676602Z","iopub.status.idle":"2023-10-24T05:23:43.070711Z","shell.execute_reply.started":"2023-10-24T05:23:37.676573Z","shell.execute_reply":"2023-10-24T05:23:43.069465Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"'It\\'s an amazing speech! I respect you, Steve. You have contributed to our World significantly. Thank You.\\namazing!\\nI can say that he is more of an Artist than a techie guy..and I can feel the impact of ISKCON (Hare Krishna) on his thoughts and life..\\nThis is Epic.. I will note each and every word.. \\n@mairug 11 by now :D\\nWhen i feel stupid i watch this speech. Nothing but so true talked by one of the most remarcable people, nowadays\\nAwesome... Nothing to say but tears were flowing out of my eyes.\\n\"and since windows just copy the mac.........\"\\nlove this quotation...\\nlol...\\n10 Microsoft employees don\\'t like this video!\\nwhoa!!\\nOne of the best speeches Ive heard. \\nGenius and King of creativtiy\\nThis is a great, gifted man. \\nCommencement speeches by the top business men in the world are what I love to watch. I will one day be giving a Commencement Speech to the next generation about business and some wise words for life. I just wish when I graduate somebody like Michael Bloomberg, Steve Jobs, Michael Dell, Larry Ellison or a Bill Gates would be giving a Commencement Speech to me.\\nthe greatest\\nThis man is the greatest blend of artist and scientist. I would put him up with Da Vinci. His design aesthetics is up there with all the greatest artists and designers but he\\'s innovated in the sciences and applied lateral learning like no other... great example in the calligraphy course.. no typical computer science geek would be into such a  course.\\n\\n\\nawesome man.......simply inspiring.\\nGreat, great message.  Thank you Mr. Jobs.  God bless.\\nGreat, great message.  Thank you Mr. Jobs.  God bless.\\nIt appears to me, that 9 people have missed the Like-button...\\nmind blowing video..........\\nSteve\\'s speech and JK Rowling\\'s speech tie for best\\nAnd since Windows simply copied Mac...hilarious!\\nvery good\\n\\nthis my 15th time iam watching this video its undoughtly inspiring .Hatts off to steve jobs\\nIt is not going on what happens ... somebody use ... NO ways ~!\\nthis is actually inspiring... saw it first way back... now it comes back all again...\\ntranslation: steve was a bum until he met wozniak, who was a brilliant young engineer who went to school, actually learned something, and had a successful career at HP.  always ready to seize an opportunity, jobs suckered wozniak into a business partnership, where wozniak would do all the work and jobs would be the obnoxious asshole who takes all the credit. the rest is history.\\nA very dear friend of mine once showed me this amazing video, and it moved me...inspired me. \\r\\nWhile my friend is no more, I see this video whenever I think I\\'m losing focus to help me get back on track...or whenever I think of my dear friend.\\nhow freakin\\' cool is this guy!?\\nstay hungry, stay foolish guys!\\nSteve Jobs has issues.\\nI wonder if he had a Ipad at the time would he use it?\\ninspirational!\\nmuito bom!\\nInsightful and heart felt.  Thanks Steve.\\nThree great storys from Steve Jobs! Great!\\ntirando a parte do puxa-saco, foi bacana\\n\"stay hungry ,stay foolish..\"....INSPIRING\\nwhat wounder\\nThird story is great. Starts at 16:23\\nI love it. A commencement speech that say\\'s it\\'s okay to drop out of college =)\\nhe is great\\nWhat would make you assume this?\\nsame as me..\\nGreat people often speak greatly, as well.\\nWhenever I lose my focus and become depressed, I spend some time watching this video and it is really very inspiring.\\nthis is the message every Human Being should keep in mind....this is what makes all the difference , and explains what we\\'re doing here.\\r\\nThank you Steve!\\nvery inspiring indeed\\nThis speech makes me cry every time I listen to it... it is too powerful and I am too sensitive, I guess. It really touches my heart, and really changes my life yet.\\r\\nThank you, Steve\\nThank you Steve Jobs! Your speech means a lot to me! It gives me strenght to go on!\\nOne of the best speaker ... perfect 10\\nSteve jobs intellectual ability is not only inspiring\\nBut Mind blowing...More grease to his elbows\\n\"Stay hungry..Stay foolish\" Brilliant!\\n\\nUnfortunately some Americans take it literally.\\nwow\\nseems this is the full version\\n'"},"metadata":{}}]},{"cell_type":"code","source":"import transformers\ntext = fetch_comments(url)\ntokenizer = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\nchunks = text_to_chunks(text, tokenizer)\nprint(\"Chunks list size: \", len(chunks))    # TODO: Remove this\n# summary = summarize_comment(chunks,524,0.1)\n# print(summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:25:15.318273Z","iopub.execute_input":"2023-10-24T05:25:15.318674Z","iopub.status.idle":"2023-10-24T05:25:18.948516Z","shell.execute_reply.started":"2023-10-24T05:25:15.318643Z","shell.execute_reply":"2023-10-24T05:25:18.947136Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Chunks list size:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"summary = summarize_comment(chunks,524,0.1)\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:27:09.409967Z","iopub.execute_input":"2023-10-24T05:27:09.410533Z","iopub.status.idle":"2023-10-24T05:27:26.026495Z","shell.execute_reply.started":"2023-10-24T05:27:09.410497Z","shell.execute_reply":"2023-10-24T05:27:26.025127Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"The comments are generally positive and praise Steve Jobs for his inspiring speech. Many people mention the impact of ISKCON (Hare Krishna) on his thoughts and life, and comment on his blend of artistic and scientific abilities. The comments also mention the impact of the speech on their lives, and how it has helped them stay focused and motivated.\n","output_type":"stream"}]},{"cell_type":"code","source":"summary = summarize_comment(chunks,524,0.7)\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T05:28:31.314203Z","iopub.execute_input":"2023-10-24T05:28:31.314613Z","iopub.status.idle":"2023-10-24T05:28:32.782373Z","shell.execute_reply.started":"2023-10-24T05:28:31.314583Z","shell.execute_reply":"2023-10-24T05:28:32.781125Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"The comments are in response to a commencement speech given by Steve Jobs. The comments praise Jobs for his contributions to the world, his blend of artistic and scientific thinking, his inspirational message, and his intellect. They also mention his speech's impact on the lives of those who have watched it.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}